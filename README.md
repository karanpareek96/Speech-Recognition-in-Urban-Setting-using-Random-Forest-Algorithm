# Speech-Recognition-in-Urban-Setting-using-Random-Forest-Algorithm

# Citation

Lui, C., Pareek, K. (2018). "Random Forest-based Voice Activity Detector". Unpublished manuscript, New York University.

# Abstract
The ​Voice Activity Detection (VAD) module has emerged as the fundamental pre-processing block for speech processing devices. This has allowed for speech recognition products such as Kaldi and Amazon Alexa to thrive in a world where speech has become one of the primary ways of accessing and using this new technology. While speech and voice detection applications employ the use of both near and far field processing, the building blocks in both cases detail the use of sophisticated signal processing that allows for recognition and real-time processing of spoken words.

The main motivation for this project arises from the fact that the number of applications that use speech and voice detection tools have risen considerably over the last few years. An opportunity to analyze this segment of signal processing using the current tools of machine learning classification algorithms presents a unique opportunity into understanding how speech detection works and what are its strengths in contrast to other audio semantic tools.

The primary goal of this study is aimed at employing the ​Random Forest Classifier​, a decision tree-based machine learning algorithm, for the detection of speech events in noisy urban environments. A number of analysis tools such as confusion matrices, ​Receiver Operating Characteristic (ROC) plots and Signal-to-Noise ratio (SNR) are used to determine the performance of the system. Towards the end of the paper, three improvements to the current method have been discussed.

# References

[1] Atal, B., & Rabiner, L. (1976). “A pattern recognition approach to voiced-unvoiced-silence classification with applications to speech recognition.” ​IEEE Transactions on Acoustics, Speech, and Signal Processing, 24(3)​, pp. 201-212

[2] Breiman, L. (2001). “Random forests.” ​Machine learning, 45(1),​ pp. 5 - 32.

[3] Common Voice by Mozilla. (n.d.). ​Retrieved from https://voice.mozilla.org/en/datasets.

[4] Dave, N. (2013). “Feature extraction methods LPC, PLP and MFCC in speech recognition.” International journal for advance research in engineering and technology, 1(6),​ pp. 1 - 4.

[5] Graf, S., Herbig, T., Buck, M., & Schmidt, G. (2015). “Features for voice activity detection: a comparative analysis.” ​EURASIP Journal on Advances in Signal Processing​, ​2015​(1), pp. 91.

[6] Lavner, Y., & Ruinskiy, D. (2009). “A decision-tree-based algorithm for speech/music classification and segmentation. ​EURASIP Journal on Audio, Speech, and Music Processing,​ 2009​, pp. 2 - 4.

[7] Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Vanderplas, J. (2011). “Scikit-learn: Machine learning in Python.” J​ournal of machine learning research, 12(Oct),​ pp. 2825 - 2830.

[8] Renevey, P., & Drygajlo, A. (2001). “Entropy-based voice activity detection in very noisy conditions.” ​Seventh European Conference on Speech Communication and Technology.​

[9] Saeedi, J., Ahadi, S. M., & Faez, K. (2015). “Robust voice activity detection directed by noise classification.” ​Signal, Image and Video Processing​, ​9​(3), pp. 561-572

[10] Salamon, J., MacConnell, D., Cartwright, M., Li, P., Bello, J. (2017). “Scraper: A Library for Soundscape Synthesis and Augmentation.” I​EEE Workshop on Applications of Signal Processing to Audio and Acoustics,​ pp. 344 - 348.

[11] Thambi, S., Sreekumar, T., Santosh, C., Reghu, R. (2014). “Random Forest Algorithm for Improving the Performance of Speech/Non-Speech Detection.” ​First International Conference on Computational Systems and Communications (ICCSC),​ pp. 28 - 32.

[12] Wang, Y., Getreuer, P., Hughes, T., Lyon, R. F., & Saurous, R. A. (2017). “Trainable frontend for robust and far-field keyword spotting.” ​2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)​, pp. 5670- 5674.
